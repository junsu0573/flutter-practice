{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamCommentsUpdateModelMaker.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awq8sMaIFHJ1"
      },
      "source": [
        "# Install Model maker\n",
        "!pip install -q tflite-model-maker &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fEAqoLLF6O9"
      },
      "source": [
        "# Imports and check that we are using TF2.x\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker import configs\n",
        "from tflite_model_maker import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import text_classifier\n",
        "from tflite_model_maker.text_classifier import DataLoader\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsuDZvjgREsS"
      },
      "source": [
        "training_data = tf.keras.utils.get_file(fname='comments-spam-extras.csv', origin='https://storage.googleapis.com/laurencemoroney-blog.appspot.com/lmblog_comments_extras.csv', extract=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbew43TbG9HQ"
      },
      "source": [
        "# Use a model spec from model maker. Options are 'mobilebert_classifier', 'bert_classifier' and 'average_word_vec'\n",
        "# The first 2 use the BERT model, which is accurate, but larger and slower to train\n",
        "# Average Word Vec is kinda like transfer learning where there are pre-trained word weights\n",
        "# and dictionaries\n",
        "spec = model_spec.get('average_word_vec')\n",
        "spec.num_words = 2000\n",
        "spec.seq_len = 20\n",
        "spec.wordvec_dim = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WdQmzTKHFVn"
      },
      "source": [
        "# Load the CSV using DataLoader.from_csv to make the training_data\n",
        "data = DataLoader.from_csv(\n",
        "      filename=training_data,\n",
        "      text_column='commenttext', \n",
        "      label_column='spam', \n",
        "      model_spec=spec,\n",
        "      delimiter=',',\n",
        "      shuffle=True,\n",
        "      is_training=True)\n",
        "\n",
        "train_data, test_data = data.split(0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qThBoIIyG_Du"
      },
      "source": [
        "# Build the model\n",
        "model = text_classifier.create(train_data, model_spec=spec, epochs=50, validation_data=test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-1eHu_OcRtW"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In-1-rzW-_9b"
      },
      "source": [
        "# This will export to SavedModel format with the model, vocabulary and labels.\n",
        "model.export(export_dir='/mm_update_spam_savedmodel/', export_format=[ExportFormat.LABEL, ExportFormat.VOCAB, ExportFormat.SAVED_MODEL])\n",
        "\n",
        "# You can find your files in colab by clicking the 'folder' tab to the left of\n",
        "# this code window, and then navigating 'up' a directory to find the root\n",
        "# directory listing -- and from there you should see /mm_update_spam_savedmodel/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the SavedModel subfolder to a version number\n",
        "!mv /mm_update_spam_savedmodel/saved_model /mm_update_spam_savedmodel/123\n",
        "!zip -r mm_update_spam_savedmodel.zip /mm_update_spam_savedmodel/ "
      ],
      "metadata": {
        "id": "klBRRgIkD-GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UNNrCWbKbxh"
      },
      "source": [
        "# Optional extra\n",
        "# You can use this cell to export details for projector.tensorflow.org\n",
        "# Where you can explore the embeddings that were learned for this dataset\n",
        "embeddings = model.model.layers[0]\n",
        "weights = embeddings.get_weights()[0]\n",
        "tokenizer = model.model_spec.vocab\n",
        "\n",
        "import io\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for word in tokenizer:\n",
        "  #word = tokenizer.decode([word_num])\n",
        "  value = tokenizer[word]\n",
        "  embeddings = weights[value]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()\n",
        "\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
